{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b5ab2b8",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ’³ Credit Card Fraud Detection with Tuned XGBoost\n",
    "\n",
    "This notebook demonstrates an end-to-end **fraud detection pipeline** using:\n",
    "- Class imbalance handling\n",
    "- Feature selection\n",
    "- Bayesian hyperparameter optimization\n",
    "- XGBoost classifier\n",
    "\n",
    "The goal is to **maximize F1-score**, not accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b44926",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Imports & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c1aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf9a6c",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Load Dataset\n",
    "\n",
    "> Dataset is not included due to size.\n",
    "> Download `creditcard.csv` from Kaggle and place it in the project root.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8f889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (284807, 31)\n",
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6274803b",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Train-Test Split & Class Imbalance Handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e082d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale pos weight: 577.2868020304569\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "print(\"Scale pos weight:\", scale_pos_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcffa8d0",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Baseline XGBoost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e5a0841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model\n",
      "[[56863     1]\n",
      " [   17    81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.99      0.83      0.90        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.91      0.95     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline_model = XGBClassifier(\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "\n",
    "baseline_model.fit(x_train, y_train)\n",
    "y_pred_base = baseline_model.predict(x_test)\n",
    "\n",
    "print(\"Baseline Model\")\n",
    "print(confusion_matrix(y_test, y_pred_base))\n",
    "print(classification_report(y_test, y_pred_base))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f727b",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Feature Selection (ANOVA F-test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2afa5bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['V3', 'V4', 'V7', 'V10', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "x_train_fs = selector.fit_transform(x_train, y_train)\n",
    "x_test_fs = selector.transform(x_test)\n",
    "\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Selected Features:\", list(selected_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdf4217",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Bayesian Optimization for Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8def8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xgb_evaluate(max_depth, learning_rate, n_estimators, scale_pos_weight):\n",
    "    model = XGBClassifier(\n",
    "        max_depth=int(max_depth),\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=int(n_estimators),\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        eval_metric=\"mlogloss\"\n",
    "    )\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        model, x_train_fs, y_train,\n",
    "        scoring=\"f1\", cv=5, n_jobs=-1\n",
    "    )\n",
    "    return scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8b54b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | learni... | n_esti... | scale_... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.6595233\u001b[39m | \u001b[39m3.4981604\u001b[39m | \u001b[39m0.2857071\u001b[39m | \u001b[39m123.19939\u001b[39m | \u001b[39m345.99898\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.1561286\u001b[39m | \u001b[39m2.6240745\u001b[39m | \u001b[39m0.0552384\u001b[39m | \u001b[39m55.808361\u001b[39m | \u001b[39m500.16588\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.4215543\u001b[39m | \u001b[39m4.4044600\u001b[39m | \u001b[39m0.2153410\u001b[39m | \u001b[39m52.058449\u001b[39m | \u001b[39m559.94624\u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m0.6780665\u001b[39m | \u001b[35m5.3297705\u001b[39m | \u001b[35m0.0715783\u001b[39m | \u001b[35m68.182496\u001b[39m | \u001b[35m106.69359\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.5236202\u001b[39m | \u001b[39m3.2169689\u001b[39m | \u001b[39m0.1621793\u001b[39m | \u001b[39m93.194501\u001b[39m | \u001b[39m168.83150\u001b[39m |\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m0.7538050\u001b[39m | \u001b[35m5.8057794\u001b[39m | \u001b[35m0.0781583\u001b[39m | \u001b[35m103.13680\u001b[39m | \u001b[35m63.116935\u001b[39m |\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m0.8166102\u001b[39m | \u001b[35m5.1632325\u001b[39m | \u001b[35m0.1788096\u001b[39m | \u001b[35m102.47810\u001b[39m | \u001b[35m63.944852\u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.6016779\u001b[39m | \u001b[39m2.3408300\u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m97.815650\u001b[39m | \u001b[39m67.497588\u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.6101848\u001b[39m | \u001b[39m2.8802835\u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m105.34289\u001b[39m | \u001b[39m67.133823\u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.6143838\u001b[39m | \u001b[39m2.2946517\u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m100.45359\u001b[39m | \u001b[39m61.502306\u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.4729688\u001b[39m | \u001b[39m2.4598850\u001b[39m | \u001b[39m0.0665757\u001b[39m | \u001b[39m65.968626\u001b[39m | \u001b[39m101.74207\u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.7956995\u001b[39m | \u001b[39m6.0      \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m99.567623\u001b[39m | \u001b[39m64.769087\u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.7475538\u001b[39m | \u001b[39m6.0      \u001b[39m | \u001b[39m0.0781799\u001b[39m | \u001b[39m70.936253\u001b[39m | \u001b[39m112.84702\u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.7790983\u001b[39m | \u001b[39m6.0      \u001b[39m | \u001b[39m0.0124231\u001b[39m | \u001b[39m64.946766\u001b[39m | \u001b[39m113.50416\u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.4886924\u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m0.3      \u001b[39m | \u001b[39m67.541354\u001b[39m | \u001b[39m117.06341\u001b[39m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgb_evaluate,\n",
    "    pbounds={\n",
    "        \"max_depth\": (2, 6),\n",
    "        \"learning_rate\": (0.01, 0.3),\n",
    "        \"n_estimators\": (50, 150),\n",
    "        \"scale_pos_weight\": (1, scale_pos_weight)\n",
    "    },\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=5, n_iter=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e55b5d",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Train Final Tuned Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e04bc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model\n",
      "[[56844    20]\n",
      " [   13    85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.81      0.87      0.84        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.90      0.93      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_params = optimizer.max[\"params\"]\n",
    "\n",
    "final_model = XGBClassifier(\n",
    "    max_depth=int(best_params[\"max_depth\"]),\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    n_estimators=int(best_params[\"n_estimators\"]),\n",
    "    scale_pos_weight=best_params[\"scale_pos_weight\"],\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "\n",
    "final_model.fit(x_train_fs, y_train)\n",
    "\n",
    "y_pred_final = final_model.predict(x_test_fs)\n",
    "\n",
    "print(\"Tuned Model\")\n",
    "print(confusion_matrix(y_test, y_pred_final))\n",
    "print(classification_report(y_test, y_pred_final))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116d23a",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Key Takeaways\n",
    "\n",
    "- Accuracy is misleading for fraud detection\n",
    "- Class imbalance must be handled explicitly\n",
    "- Feature selection improves robustness\n",
    "- Bayesian Optimization is efficient for tuning\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
